<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="The parallelism degree of the implementation, detected at runtime. If you hash your inputs in small batches, making the batch size a multiple of `degree` will generally give good performance."><title>degree in blake2b_simd::many - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2"href="../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../static.files/rustdoc-ca0dd0c4.css"><meta name="rustdoc-vars" data-root-path="../../" data-static-root-path="../../static.files/" data-current-crate="blake2b_simd" data-themes="" data-resource-suffix="" data-rustdoc-version="1.92.0 (ded5c06cf 2025-12-08)" data-channel="1.92.0" data-search-js="search-d69d8955.js" data-stringdex-js="stringdex-c3e638e9.js" data-settings-js="settings-c38705f0.js" ><script src="../../static.files/storage-e2aeef58.js"></script><script defer src="sidebar-items.js"></script><script defer src="../../static.files/main-ce535bd0.js"></script><noscript><link rel="stylesheet" href="../../static.files/noscript-263c88ec.css"></noscript><link rel="alternate icon" type="image/png" href="../../static.files/favicon-32x32-eab170b8.png"><link rel="icon" type="image/svg+xml" href="../../static.files/favicon-044be391.svg"></head><body class="rustdoc fn"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><rustdoc-topbar><h2><a href="#">degree</a></h2></rustdoc-topbar><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../../blake2b_simd/index.html">blake2b_<wbr>simd</a><span class="version">1.0.4</span></h2></div><div class="sidebar-elems"><div id="rustdoc-modnav"><h2><a href="index.html">In blake2b_<wbr>simd::<wbr>many</a></h2></div></div></nav><div class="sidebar-resizer" title="Drag to resize sidebar"></div><main><div class="width-limiter"><section id="main-content" class="content"><div class="main-heading"><div class="rustdoc-breadcrumbs"><a href="../index.html">blake2b_simd</a>::<wbr><a href="index.html">many</a></div><h1>Function <span class="fn">degree</span>&nbsp;<button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../../src/blake2b_simd/many.rs.html#91-93">Source</a> </span></div><pre class="rust item-decl"><code>pub fn degree() -&gt; <a class="primitive" href="https://doc.rust-lang.org/1.92.0/std/primitive.usize.html">usize</a></code></pre><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>The parallelism degree of the implementation, detected at runtime. If you
hash your inputs in small batches, making the batch size a multiple of
<code>degree</code> will generally give good performance.</p>
<p>For example, an x86 processor that supports AVX2 can compute four BLAKE2b
hashes in parallel, so <code>degree</code> returns 4 on that machine. If you call
<a href="fn.hash_many.html"><code>hash_many</code></a> with only three inputs, thatâ€™s not enough to use the AVX2
implementation, and your average throughput will be lower. Likewise if you
call it with five inputs of equal length, the first four will be hashed in
parallel with AVX2, but the last one will have to be hashed by itself, and
again your average throughput will be lower.</p>
<p>As noted in the module level docs, performance is more complicated if your
inputs are of different lengths. When parallelizing long and short inputs
together, the longer ones will have bytes left over, and the implementation
will try to parallelize those leftover bytes with subsequent inputs. The
more inputs available in that case, the more the implementation will be
able to parallelize.</p>
<p>If you need a constant batch size, for example to collect inputs in an
array, see <a href="constant.MAX_DEGREE.html"><code>MAX_DEGREE</code></a>.</p>
</div></details></section></div></main></body></html>